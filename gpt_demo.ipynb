{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b97e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from transformers import GPT2Model, GPT2Tokenizer, AutoTokenizer, AutoModelForCausalLM, AutoModelWithLMHead\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import random\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3fb8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeting seed for PyTorch, Python i Numpy\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cda3af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_sentiment(value):\n",
    "    if value.startswith('+'):\n",
    "        return 'positive'\n",
    "    elif value.startswith('-'):\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0939874",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"podaci_trening.csv\")\n",
    "df['label'] = df['label'].apply(transform_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34346fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>1-1</td>\n",
       "      <td>♥ Znao sam da će ovaj biti prvi! :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>1-2</td>\n",
       "      <td>pa mora... The Dude Abides! :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>1-6</td>\n",
       "      <td>Film gledam već godinama i svaki put otkrijem ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>1-7</td>\n",
       "      <td>Svaki faktor je podjednako krucijalan i savrše...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>1-8</td>\n",
       "      <td>john goodman je obeležio ovaj film sa svojim p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label   id                                               text\n",
       "0  positive  1-1                ♥ Znao sam da će ovaj biti prvi! :)\n",
       "1  positive  1-2                     pa mora... The Dude Abides! :)\n",
       "2  positive  1-6  Film gledam već godinama i svaki put otkrijem ...\n",
       "3  positive  1-7  Svaki faktor je podjednako krucijalan i savrše...\n",
       "4  positive  1-8  john goodman je obeležio ovaj film sa svojim p..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ca3c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('macedonizer/sr-gpt2')\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('JeRTeh/sr-gpt2-large')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"datatab/gpt2-serbian-base\")\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained(\"procesaur/gpt2-srlat\")\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14ff0f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('macedonizer/sr-gpt2')\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large')\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"JeRTeh/sr-gpt2-large\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"datatab/gpt2-serbian-base\")\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained(\"procesaur/gpt2-srlat\")\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "labels = { \"positive\": 0, \"negative\": 1 }\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.labels = [labels[label] for label in df['label']]\n",
    "        self.texts = [tokenizer(text,\n",
    "                                padding='max_length',\n",
    "                                max_length=128,\n",
    "                                truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['text']]\n",
    "        \n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.texts[idx]\n",
    "        batch_y = torch.tensor(self.labels[idx], dtype=torch.long)  # Konvertujemo u torch.long\n",
    "        return batch_texts, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51c7aebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2792 349 349\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=35),\n",
    "                                     [int(0.8*len(df)), int(0.9*len(df))])\n",
    "\n",
    "print(len(df_train), len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ad0093e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2792 698 464\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(112)\n",
    "df_train, df_val = np.split(df.sample(frac=1, random_state=35),\n",
    "                            [int(0.8*len(df))])\n",
    "\n",
    "df_test = pd.read_csv(\"podaci_test.csv\")\n",
    "df_test = df_test[['1', 'comment']]\n",
    "df_test = df_test.rename(columns = {'1' : 'label', 'comment' : 'text'})\n",
    "df_test['label'] = df_test['label'].apply(transform_sentiment)\n",
    "\n",
    "print(len(df_train), len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9903f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGPT2SequenceClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size: int, num_classes:int ,max_seq_len:int, gpt_model_name:str):\n",
    "        super(SimpleGPT2SequenceClassifier,self).__init__()\n",
    "        self.gpt2model = GPT2Model.from_pretrained(gpt_model_name)\n",
    "        # self.gpt2model = AutoModelForCausalLM.from_pretrained(gpt_model_name)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size*max_seq_len, num_classes)\n",
    "        \n",
    "    def forward(self, input_id, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "                input_id: encoded inputs ids of sent.\n",
    "        \"\"\"\n",
    "        gpt_out, _ = self.gpt2model(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
    "        batch_size = gpt_out.shape[0]\n",
    "        linear_output = self.fc1(gpt_out.view(batch_size,-1))\n",
    "        return linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c960c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "    \n",
    "    # use_cuda = torch.cuda.is_available()\n",
    "    # device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    device = 'cuda'\n",
    "    use_cuda = True\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "        \n",
    "        for train_input, train_label in tqdm(train_dataloader):\n",
    "            train_label = train_label.to(device)\n",
    "            mask = train_input['attention_mask'].to(device)\n",
    "            input_id = train_input[\"input_ids\"].squeeze(1).to(device)\n",
    "            \n",
    "            model.zero_grad()\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            \n",
    "            batch_loss = criterion(output, train_label)\n",
    "            total_loss_train += batch_loss.item()\n",
    "            \n",
    "            acc = (output.argmax(dim=1)==train_label).sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for val_input, val_label in val_dataloader:\n",
    "                val_label = val_label.to(device)\n",
    "                mask = val_input['attention_mask'].to(device)\n",
    "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "                \n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, val_label)\n",
    "                total_loss_val += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1)==val_label).sum().item()\n",
    "                total_acc_val += acc\n",
    "                \n",
    "            print(\n",
    "            f\"Epochs: {epoch_num + 1} | Train Loss: {total_loss_train/len(train_data): .3f} \\\n",
    "            | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "            | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "            | Val Accuracy: {total_acc_val / len(val_data): .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "76923fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1396 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15600\\4100922323.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mLR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15600\\255576028.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_data, val_data, learning_rate, epochs)\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15600\\2448635612.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_id, mask)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0minput_id\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mencoded\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mids\u001b[0m \u001b[0mof\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \"\"\"\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mgpt_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpt2model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpt_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mlinear_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpt_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1078\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[0;32m   1081\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 846\u001b[1;33m             \u001b[0minputs_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwte\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    847\u001b[0m         \u001b[0mposition_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwpe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    848\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mposition_embeds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2042\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2043\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2044\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "model = SimpleGPT2SequenceClassifier(hidden_size=768, num_classes = 2, max_seq_len=128, gpt_model_name=\"gpt2\")\n",
    "LR = 1e-5\n",
    "\n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9319eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "        \n",
    "    # Tracking variables\n",
    "    predictions_labels = []\n",
    "    true_labels = []\n",
    "    \n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "            \n",
    "            # add original labels\n",
    "            true_labels += test_label.cpu().numpy().flatten().tolist()\n",
    "            # get predicitons to list\n",
    "            predictions_labels += output.argmax(dim=1).cpu().numpy().flatten().tolist()\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    return true_labels, predictions_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1503c37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.608\n"
     ]
    }
   ],
   "source": [
    "true_labels, pred_labels = evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b90f5352",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [05:55<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.344             | Train Accuracy:  0.586             | Val Loss:  0.310             | Val Accuracy:  0.653\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "model = SimpleGPT2SequenceClassifier(hidden_size = 768, num_classes=2, max_seq_len = 128, gpt_model_name=\"datatab/gpt2-serbian-base\")\n",
    "LR = 1e-5\n",
    "\n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5fb9081b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.573\n"
     ]
    }
   ],
   "source": [
    "true_labels, pred_labels = evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "57a53ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [05:48<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.349             | Train Accuracy:  0.585             | Val Loss:  0.347             | Val Accuracy:  0.640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [05:33<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.276             | Train Accuracy:  0.718             | Val Loss:  0.323             | Val Accuracy:  0.653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [04:49<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.199             | Train Accuracy:  0.822             | Val Loss:  0.310             | Val Accuracy:  0.685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:54<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.102             | Train Accuracy:  0.915             | Val Loss:  0.411             | Val Accuracy:  0.662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:54<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.052             | Train Accuracy:  0.961             | Val Loss:  0.469             | Val Accuracy:  0.666\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "model = SimpleGPT2SequenceClassifier(hidden_size = 768, num_classes=2, max_seq_len = 128, gpt_model_name=\"datatab/gpt2-serbian-base\")\n",
    "LR = 1e-5\n",
    "\n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "afad7ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.642\n"
     ]
    }
   ],
   "source": [
    "true_labels, pred_labels = evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9ec3e9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:58<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.343             | Train Accuracy:  0.596             | Val Loss:  0.300             | Val Accuracy:  0.650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:55<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.265             | Train Accuracy:  0.739             | Val Loss:  0.310             | Val Accuracy:  0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:55<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.157             | Train Accuracy:  0.864             | Val Loss:  0.417             | Val Accuracy:  0.679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:52<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.070             | Train Accuracy:  0.947             | Val Loss:  0.499             | Val Accuracy:  0.669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:52<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.036             | Train Accuracy:  0.974             | Val Loss:  0.576             | Val Accuracy:  0.679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:52<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 | Train Loss:  0.017             | Train Accuracy:  0.989             | Val Loss:  0.625             | Val Accuracy:  0.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:53<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 | Train Loss:  0.021             | Train Accuracy:  0.989             | Val Loss:  0.571             | Val Accuracy:  0.659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:53<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 | Train Loss:  0.017             | Train Accuracy:  0.988             | Val Loss:  0.625             | Val Accuracy:  0.656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:54<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 | Train Loss:  0.006             | Train Accuracy:  0.997             | Val Loss:  0.791             | Val Accuracy:  0.668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:53<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 | Train Loss:  0.001             | Train Accuracy:  1.000             | Val Loss:  0.838             | Val Accuracy:  0.689\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model = SimpleGPT2SequenceClassifier(hidden_size = 768, num_classes=2, max_seq_len = 128, gpt_model_name=\"datatab/gpt2-serbian-base\")\n",
    "LR = 1e-5\n",
    "\n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed51709e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.631\n"
     ]
    }
   ],
   "source": [
    "true_labels, pred_labels = evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f62d4eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:53<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.351             | Train Accuracy:  0.603             | Val Loss:  0.310             | Val Accuracy:  0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:52<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.270             | Train Accuracy:  0.727             | Val Loss:  0.384             | Val Accuracy:  0.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:52<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.181             | Train Accuracy:  0.829             | Val Loss:  0.361             | Val Accuracy:  0.660\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "model = SimpleGPT2SequenceClassifier(hidden_size = 768, num_classes=2, max_seq_len = 128, gpt_model_name=\"datatab/gpt2-serbian-base\")\n",
    "LR = 1e-5\n",
    "\n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57aa6a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.644\n"
     ]
    }
   ],
   "source": [
    "true_labels, pred_labels = evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5180cb83",
   "metadata": {},
   "source": [
    "<h3>Dodavanje pooling sloja</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "470a5d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleGPT2SequenceClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size: int, num_classes:int ,max_seq_len:int, gpt_model_name:str):\n",
    "        super(SimpleGPT2SequenceClassifier,self).__init__()\n",
    "        self.gpt2model = GPT2Model.from_pretrained(gpt_model_name)\n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)  # Global average pooling\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, input_id, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_id: encoded input ids of sent.\n",
    "        \"\"\"\n",
    "        gpt_out, _ = self.gpt2model(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
    "        gpt_out = gpt_out.permute(0, 2, 1)  # Permute to (batch_size, hidden_size, seq_len)\n",
    "        pooled_output = self.pooling(gpt_out).squeeze(-1)  # Apply pooling and remove singleton dimension\n",
    "        linear_output = self.fc1(pooled_output)\n",
    "        return linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d967909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [05:04<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.320             | Train Accuracy:  0.621             | Val Loss:  0.299             | Val Accuracy:  0.649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [05:10<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.276             | Train Accuracy:  0.704             | Val Loss:  0.287             | Val Accuracy:  0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [05:09<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.222             | Train Accuracy:  0.789             | Val Loss:  0.305             | Val Accuracy:  0.673\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "model = SimpleGPT2SequenceClassifier(hidden_size = 768, num_classes=2, max_seq_len = 128, gpt_model_name=\"datatab/gpt2-serbian-base\")\n",
    "LR = 1e-5\n",
    "\n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d246d8",
   "metadata": {},
   "source": [
    "<h3>Dodavanje dropout sloja</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "406ca6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGPT2SequenceClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size: int, num_classes:int ,max_seq_len:int, gpt_model_name:str):\n",
    "        super(SimpleGPT2SequenceClassifier,self).__init__()\n",
    "        self.gpt2model = GPT2Model.from_pretrained(gpt_model_name)\n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout = nn.Dropout(0.2)  # Add dropout with 20% probability\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, input_id, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_id: encoded input ids of sent.\n",
    "        \"\"\"\n",
    "        gpt_out, _ = self.gpt2model(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
    "        gpt_out = gpt_out.permute(0, 2, 1)\n",
    "        pooled_output = self.pooling(gpt_out).squeeze(-1)\n",
    "        pooled_output = self.dropout(pooled_output)  # Apply dropout\n",
    "        linear_output = self.fc1(pooled_output)\n",
    "        return linear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c17af99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [04:52<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.326             | Train Accuracy:  0.613             | Val Loss:  0.305             | Val Accuracy:  0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [04:52<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.279             | Train Accuracy:  0.691             | Val Loss:  0.291             | Val Accuracy:  0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [05:05<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.229             | Train Accuracy:  0.779             | Val Loss:  0.289             | Val Accuracy:  0.678\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "model = SimpleGPT2SequenceClassifier(hidden_size = 768, num_classes=2, max_seq_len = 128, gpt_model_name=\"datatab/gpt2-serbian-base\")\n",
    "LR = 1e-5\n",
    "\n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f059eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.675\n"
     ]
    }
   ],
   "source": [
    "true_labels, pred_labels = evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecda9816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:59<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.326             | Train Accuracy:  0.613             | Val Loss:  0.305             | Val Accuracy:  0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:53<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.279             | Train Accuracy:  0.691             | Val Loss:  0.291             | Val Accuracy:  0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:53<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.229             | Train Accuracy:  0.779             | Val Loss:  0.289             | Val Accuracy:  0.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:53<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.150             | Train Accuracy:  0.870             | Val Loss:  0.338             | Val Accuracy:  0.679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:53<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.082             | Train Accuracy:  0.935             | Val Loss:  0.491             | Val Accuracy:  0.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:53<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 | Train Loss:  0.048             | Train Accuracy:  0.962             | Val Loss:  0.632             | Val Accuracy:  0.698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:53<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 | Train Loss:  0.034             | Train Accuracy:  0.977             | Val Loss:  0.655             | Val Accuracy:  0.673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:53<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 | Train Loss:  0.037             | Train Accuracy:  0.974             | Val Loss:  0.575             | Val Accuracy:  0.702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:53<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 | Train Loss:  0.021             | Train Accuracy:  0.987             | Val Loss:  0.957             | Val Accuracy:  0.665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:53<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 | Train Loss:  0.032             | Train Accuracy:  0.980             | Val Loss:  0.783             | Val Accuracy:  0.666\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model = SimpleGPT2SequenceClassifier(hidden_size = 768, num_classes=2, max_seq_len = 128, gpt_model_name=\"datatab/gpt2-serbian-base\")\n",
    "LR = 1e-5\n",
    "\n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3421749e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.662\n"
     ]
    }
   ],
   "source": [
    "true_labels, pred_labels = evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fcbcae",
   "metadata": {},
   "source": [
    "<h3>Dodavanje strategije za inicijalizaciju tezina</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ba160bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGPT2SequenceClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size: int, num_classes:int ,max_seq_len:int, gpt_model_name:str):\n",
    "        super(SimpleGPT2SequenceClassifier,self).__init__()\n",
    "        self.gpt2model = GPT2Model.from_pretrained(gpt_model_name)\n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_size, num_classes)\n",
    "        # Initialize the weights of the fully connected layer with Xavier initialization\n",
    "        init.xavier_uniform_(self.fc1.weight)\n",
    "        \n",
    "    def forward(self, input_id, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_id: encoded input ids of sent.\n",
    "        \"\"\"\n",
    "        gpt_out, _ = self.gpt2model(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
    "        gpt_out = gpt_out.permute(0, 2, 1)\n",
    "        pooled_output = self.pooling(gpt_out).squeeze(-1)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        linear_output = self.fc1(pooled_output)\n",
    "        return linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74d54678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:55<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.403             | Train Accuracy:  0.595             | Val Loss:  0.326             | Val Accuracy:  0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:52<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.316             | Train Accuracy:  0.667             | Val Loss:  0.431             | Val Accuracy:  0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1396/1396 [03:53<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.276             | Train Accuracy:  0.719             | Val Loss:  0.295             | Val Accuracy:  0.658\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "model = SimpleGPT2SequenceClassifier(hidden_size = 768, num_classes=2, max_seq_len = 128, gpt_model_name=\"datatab/gpt2-serbian-base\")\n",
    "LR = 1e-5\n",
    "\n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "754f475d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.642\n"
     ]
    }
   ],
   "source": [
    "true_labels, pred_labels = evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc244216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
